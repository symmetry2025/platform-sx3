# Symmetry Trainer — план оптимизации нагрузки и подготовки к масштабированию

Документ фиксирует технический план работ для устойчивой работы приложения при **сотнях одновременных пользователей** и дальнейшем росте.

Контекст по текущей архитектуре (на момент написания):
- Приложение: **Next.js (App Router)**, FE+BE в одном сервисе, API под `/api/*`.
- База: **Postgres** + **Prisma**.
- Сессии: cookie-токен, валидация через таблицу `Session` (DB-backed sessions).
- Прогресс: `TrainerProgress` (JSONB, уникально по `(userId, trainerId)`).
- Лог попыток: `TrainerAttempt` (JSONB `result`, растущий event log).
- На странице может быть порядка **100 упражнений**, планируется **статистика из БД**.

## Цели и допущения

### Целевая модель нагрузки
- Деплой: **один Docker-контейнер** (в перспективе возможен горизонтальный скейл).
- Поведение пользователя: максимум **1 тренажёр за 3–4 минуты** (средняя частота записи результата низкая).
- Основные пики ожидаются не от записи результата, а от **массовых открытий страниц** (листинги/статистика) и **fan-out запросов**.

### SLO (для контроля изменений)
- **API p95**: < 200–300ms на основных ручках.
- **Ошибки**: < 0.1% на пике.
- **Postgres**: без постоянного давления на CPU/IO (ориентир < 60–70% CPU на пике), отсутствие “штормов” соединений.

## Главные риски и узкие места (приоритетно)

### A. Fan-out гидрации прогресса на страницах списков
Сейчас гидрация может делать много параллельных запросов (до ~100) к `/api/progress/trainer/:id`.
Каждый такой запрос в худшем случае включает:
- DB-check сессии (`Session` по `tokenHash`)
- чтение `TrainerProgress`

Это создаёт **пиковые bursts** при массовом входе пользователей/класса.

### A. DB-backed sessions без кэша
`getCurrentUserOrNull()` делает запрос к таблице `Session`. При росте числа API/SSR вызовов это становится заметным и по latency, и по количеству коннектов/запросов.

### B. Запись прогресса (`/api/progress/record`) — несколько операций в БД
Текущий “hot path” записи результата:
- insert `TrainerAttempt`
- read `TrainerProgress`
- upsert `TrainerProgress`

Плюс потенциальный риск **lost update** (read-modify-write по JSON при параллельных апдейтах).

### B. Статистика из БД и рост `TrainerAttempt`
`TrainerAttempt` — бесконечно растущий event log. Если строить статистику через “скан попыток и агрегацию” на лету, со временем это начнёт упираться в IO и длительность запросов.

### C. CPU-пики на bcrypt (логин/регистрация)
Не постоянная нагрузка, но может дать пики при массовом логине, без rate limit.

## План работ (по этапам)

### Этап 0 — Зафиксировать сценарии и нагрузочные цели (0.5 дня)
- Описать целевые сценарии:
  - массовый заход на листинг (100 упражнений)
  - прохождение тренажёра и запись результата (~раз в 3–4 минуты)
  - открытие экрана статистики
- Зафиксировать бюджеты по latency и RPS на ручки.

### Этап 1 — Наблюдаемость (1–2 дня)
Цель: иметь данные, чтобы оптимизировать не “на глаз”.

- **API-метрики**:
  - latency p50/p95/p99 по маршрутам `/api/*`
  - частота запросов по маршрутам
  - коды ответов (4xx/5xx)
- **DB-метрики**:
  - включить `pg_stat_statements`
  - slow query log (порог согласовать)
  - мониторинг активных соединений
- **Трассировка проблем**:
  - корреляционный id (если есть) или минимальный request id в логах
  - логировать только безопасные данные (без PII/секретов)

Критерий готовности:
- можем ответить “топ запросов в БД по total time” и “топ маршрутов по p95”.

### Этап 2 — Убрать fan-out: batch-гидрация прогресса (1–3 дня) **[самый большой выигрыш]**
Цель: 1 запрос на страницу вместо N (до 100).

- **Новый эндпоинт**: `POST /api/progress/hydrate` (или `/api/progress/batch`)
  - input: `{ trainerIds: string[] }` (лимитировать, например 200)
  - output: `{ progressByTrainerId: Record<string, AnyProgress | null> }`
- **DTO/схемы**: строго через `@smmtry/shared` (packages/shared) + синхронно обновить FE/BE.
- **Клиент**:
  - заменить `Promise.allSettled(toHydrate.map(hydrateProgressFromDb))` на один fetch
  - после ответа разложить прогресс в localStorage (как делает существующая гидрация)
- **Защита**:
  - дедуп trainerIds на клиенте/сервере
  - лимит размера тела запроса/массива
  - таймаут на запрос

Критерий готовности:
- при открытии листинга в DevTools видно **1 запрос** к `/api/progress/hydrate`, а не 100.

### Этап 3 — Сессии: снизить DB-hit’ы на каждый запрос (1–3 дня)
Цель: уменьшить нагрузку на таблицу `Session` и общий DB pressure.

Варианты (по нарастающей “готовности к масштабированию”):
- **3.1 Быстрый win (для 1 Docker)**: in-memory TTL/LRU cache `tokenHash -> user` на 30–60 секунд.
  - достаточен, чтобы резко снизить повторные чтения `Session` при bursts
  - TTL ограничивает окно неконсистентности
- **3.2 Для горизонтального скейла**: Redis cache с TTL.
- **3.3 Стратегически**: JWT (stateless), если модель безопасности это допускает.

Критерий готовности:
- число запросов к таблице `Session` заметно падает, p95 на `/api/progress/*` улучшается.

### Этап 4 — Надёжность и эффективность записи результата (1–2 дня)
Цель: корректность под конкурентными запросами + меньше round-trips.

- Обернуть запись attempt + апдейт прогресса в **транзакцию**.
- Устранить возможный **lost update** прогресса:
  - вариант: “читать-обновлять-писать” под транзакцией с блокировкой строки прогресса
  - вариант: нормализовать прогресс (полями) или использовать атомарные апдейты (если останется JSONB)
- Убедиться, что `attemptId`-дедуп стабилен и не создаёт лишнюю нагрузку при повторной отправке.

Критерий готовности:
- тест/скрипт “10 параллельных `/record` на одного пользователя” не теряет прогресс.

### Этап 5 — Статистика из БД: перейти на агрегаты, а не “скан лога” (2–5 дней)
Цель: чтобы рост `TrainerAttempt` не ухудшал p95 статистики.

Рекомендуемая схема:
- `TrainerAttempt` остаётся как **event log** (для деталей/аудита).
- Добавить **агрегатные таблицы**, например:
  - `UserDailyStats(userId, date, solved, correct, totalTimeSec, ...)`
  - `UserTrainerStats(userId, trainerId, attempts, wins, bestAccuracy, bestTimeSec, updatedAt, ...)`
- Обновлять агрегаты **в момент `/api/progress/record`** (в той же транзакции).
- Нормализовать ключевые метрики из JSONB `result` в колонки (как минимум для индексации и простых SUM/AVG).

Критерий готовности:
- экран статистики обслуживается быстрыми SELECT по агрегатам; `TrainerAttempt` читается ограниченно (или не читается вообще для summary).

### Этап 6 — Индексы, ретеншн и рост данных (0.5–2 дня сейчас + по мере роста)
Подготовка под реальные запросы:
- Индексы для `TrainerAttempt` (ориентир):
  - `(userId, createdAt DESC)`
  - `(userId, trainerId, createdAt DESC)` (если будет детализация по тренажёрам)
- Политика хранения:
  - ретеншн (например 90/180 дней) или архивирование
  - при больших объёмах: партиционирование по времени (месяц/неделя)

Критерий готовности:
- EXPLAIN типовых запросов статистики использует индексы, нет seq scan по большой таблице.

### Этап 7 — Нагрузочное тестирование (после Этапов 1–3, затем регулярно)
Инструмент: k6 (или аналог).

Сценарии:
- “Открытие листинга на 100 упражнений” (бурст)
- “1 прохождение / 3–4 минуты” (steady-state)
- “Открытие статистики” (после внедрения агрегатов)

Снимаемые метрики:
- p95/p99 по `/api/progress/hydrate`, `/api/progress/record`, `/api/stats/*`
- активные коннекты к Postgres
- top запросов в БД по total time/calls

## Рекомендуемый порядок внедрения (минимум для надёжного роста)
1) Batch-гидрация прогресса (убрать 100× запросов)
2) TTL-кэш сессии (снизить DB-hit на `Session`)
3) Агрегаты для статистики + нормализация метрик (чтобы не сканировать `TrainerAttempt`)
4) Индексы + ретеншн/архив (под рост)
5) Регулярный load-test + контроль регрессий

## Checklist “готовность к 500 CCU” (практический)
- [ ] Листинг (100 упражнений) делает 1 запрос на прогресс (batch)
- [ ] DB-check сессии кэшируется (TTL) или stateless
- [ ] `/api/progress/record` транзакционный, без lost update
- [ ] Статистика читается из агрегатов, а не из полного лога
- [ ] Есть pg_stat_statements + базовые метрики API/DB
- [ ] Есть k6-сценарий и цифры p95/p99 на целевой нагрузке

